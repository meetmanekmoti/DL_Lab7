{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Handwritten digits classification using neural network\n",
    "In this notebook we will classify handwritten digits using a simple neural network which has only input and output layers. We will than add a hidden layer and see how the performance of the model improves\n",
    "\n",
    "\n",
    "<img src=\"images/digits_nn.jpg\" style=\"width:750px;height:500px;\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train) , (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22ca841e828>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "        0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117647,\n",
       "        0.36862745, 0.60392157, 0.66666667, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235294, 0.6745098 ,\n",
       "        0.99215686, 0.94901961, 0.76470588, 0.25098039, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215686, 0.93333333, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.98431373, 0.36470588, 0.32156863,\n",
       "        0.32156863, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882353, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.77647059,\n",
       "        0.71372549, 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31372549, 0.61176471,\n",
       "        0.41960784, 0.99215686, 0.99215686, 0.80392157, 0.04313725,\n",
       "        0.        , 0.16862745, 0.60392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509804, 0.99215686, 0.74509804, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313725, 0.74509804, 0.99215686, 0.2745098 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.1372549 , 0.94509804, 0.88235294,\n",
       "        0.62745098, 0.42352941, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764706, 0.94117647,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
       "        0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.36470588, 0.98823529, 0.99215686, 0.73333333,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.97647059, 0.99215686, 0.97647059,\n",
       "        0.25098039, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980392, 0.71764706, 0.99215686, 0.99215686, 0.81176471,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.58039216, 0.89803922,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.71372549,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882353,\n",
       "        0.83529412, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.77647059, 0.31764706, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058824, 0.85882353, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.76470588, 0.31372549,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568627,\n",
       "        0.6745098 , 0.88627451, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156863, 0.04313725, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333333,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137255, 0.52941176,\n",
       "        0.51764706, 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flattened = X_train.reshape(len(X_train), 28*28)\n",
    "X_test_flattened = X_test.reshape(len(X_test), 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_flattened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "       0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "       0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.14117647, 0.36862745, 0.60392157,\n",
       "       0.66666667, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.88235294, 0.6745098 , 0.99215686, 0.94901961,\n",
       "       0.76470588, 0.25098039, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19215686, 0.93333333,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.98431373, 0.36470588,\n",
       "       0.32156863, 0.32156863, 0.21960784, 0.15294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.85882353, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.71372549,\n",
       "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31372549, 0.61176471, 0.41960784, 0.99215686, 0.99215686,\n",
       "       0.80392157, 0.04313725, 0.        , 0.16862745, 0.60392157,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "       0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54509804,\n",
       "       0.99215686, 0.74509804, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04313725, 0.74509804, 0.99215686,\n",
       "       0.2745098 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.1372549 , 0.94509804, 0.88235294, 0.62745098,\n",
       "       0.42352941, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31764706, 0.94117647, 0.99215686, 0.99215686, 0.46666667,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
       "       0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0627451 , 0.36470588,\n",
       "       0.98823529, 0.99215686, 0.73333333, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.97647059, 0.99215686,\n",
       "       0.97647059, 0.25098039, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18039216, 0.50980392,\n",
       "       0.71764706, 0.99215686, 0.99215686, 0.81176471, 0.00784314,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
       "       0.58039216, 0.89803922, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.98039216, 0.71372549, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.25882353, 0.83529412, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.31764706,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.67058824, 0.85882353,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.76470588,\n",
       "       0.31372549, 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21568627, 0.6745098 ,\n",
       "       0.88627451, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.95686275, 0.52156863, 0.04313725, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.53333333, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.83137255, 0.52941176, 0.51764706, 0.0627451 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_flattened[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.4906 - acc: 0.8764\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.3066 - acc: 0.9157\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.2860 - acc: 0.9209\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.2754 - acc: 0.9241\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.2680 - acc: 0.9258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22ca84b0b38>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(10, input_shape=(784,), activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_flattened, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 43us/sample - loss: 0.2685 - acc: 0.9254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2684975407600403, 0.9254]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_flattened, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.6570091e-05, 0.0000000e+00, 2.8908253e-05, 1.3007730e-02,\n",
       "       9.2387199e-07, 5.4389238e-05, 0.0000000e+00, 7.2496837e-01,\n",
       "       8.1032515e-05, 1.0951161e-03], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = model.predict(X_test_flattened)\n",
    "y_predicted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22ca3c3e828>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_predicted[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_labels = [np.argmax(i) for i in y_predicted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 2, 1, 0, 4]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.2933 - acc: 0.9173\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.1400 - acc: 0.9592\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.0995 - acc: 0.9705\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0775 - acc: 0.9765\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.0614 - acc: 0.9809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22cc5a6e588>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(100, input_shape=(784,), activation='relu'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_flattened, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 87us/sample - loss: 0.0931 - acc: 0.9712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09311645935631822, 0.9712]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_flattened,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Flatten layer so that we don't have to call .reshape on input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 0.2851 - acc: 0.9223\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.1296 - acc: 0.9620\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.0939 - acc: 0.9714\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 78us/sample - loss: 0.0711 - acc: 0.9788\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 75us/sample - loss: 0.0577 - acc: 0.9819\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0470 - acc: 0.9855\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.0388 - acc: 0.9882\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.0319 - acc: 0.9907\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0271 - acc: 0.9919\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0248 - acc: 0.9926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22cc5ef1cf8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 51us/sample - loss: 0.0830 - acc: 0.9756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08300045899330871, 0.9756]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
